# AI æœ‹å‹åœˆå®Œæ•´æµç¨‹æŒ‡å—

ä»ç”¨æˆ·å‘èµ·å¯¹è¯åˆ° AI å›å¤çš„å®Œæ•´æŠ€æœ¯è·¯å¾„è§£æ

## ğŸ—ºï¸ æµç¨‹æ€»è§ˆ

```
ç”¨æˆ·è¾“å…¥ â†’ APIè°ƒç”¨ â†’ æ•°æ®åº“å­˜å‚¨ â†’ AIç¼–æ’ â†’ æ¨¡å‹è°ƒç”¨ â†’ æµå¼è¿”å› â†’ å‰ç«¯æ˜¾ç¤º
```

## ğŸ“‹ è¯¦ç»†æµç¨‹æ‹†è§£

### 1. ç”¨æˆ·å‘èµ·å¯¹è¯ ğŸš€

#### æ­¥éª¤ 1ï¼šåˆ›å»ºå¯¹è¯

**ç”¨æˆ·æ“ä½œ**: è®¿é—®é¦–é¡µ â†’ å¡«å†™å¯¹è¯ä¸»é¢˜ â†’ ç‚¹å‡»"å¼€å§‹å¯¹è¯"

**å‰ç«¯ä»£ç **: `src/app/page.tsx` ç¬¬ 16-43 è¡Œ

```typescript
const handleCreateConversation = async () => {
  const response = await fetch("/api/conversations", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      title: title.trim(),
      mode: "empathy", // é»˜è®¤å…±æƒ…æ¨¡å¼
    }),
  });
  const data = await response.json();
  router.push(`/chat/${data.id}`); // è·³è½¬åˆ°èŠå¤©é¡µé¢
};
```

**åç«¯å¤„ç†**: `src/app/api/conversations/route.ts`

```typescript
export async function POST(request: NextRequest) {
  const { title, mode } = await request.json();

  // 1. æ‰¾åˆ°é»˜è®¤ç”¨æˆ·
  const user = await prisma.user.findUnique({
    where: { email: "test@example.com" },
  });

  // 2. åˆ›å»ºå¯¹è¯è®°å½•
  const conversation = await prisma.conversation.create({
    data: {
      userId: user.id,
      title, // "å·¥ä½œå‹åŠ›å¾ˆå¤§"
      mode, // "empathy"
    },
  });

  return NextResponse.json({ id: conversation.id });
}
```

**æ•°æ®åº“å˜åŒ–**:

```sql
-- conversations è¡¨æ–°å¢ä¸€æ¡è®°å½•
INSERT INTO conversations (id, userId, title, mode, createdAt)
VALUES ('conv_123', 'user_1', 'å·¥ä½œå‹åŠ›å¾ˆå¤§', 'empathy', NOW());
```

---

### 2. ç”¨æˆ·å‘é€æ¶ˆæ¯ ğŸ’¬

#### æ­¥éª¤ 2ï¼šå‘é€ç”¨æˆ·æ¶ˆæ¯

**ç”¨æˆ·æ“ä½œ**: åœ¨èŠå¤©é¡µé¢è¾“å…¥æ¶ˆæ¯ â†’ ç‚¹å‡»å‘é€

**å‰ç«¯ä»£ç **: `src/app/chat/[id]/page.tsx` ç¬¬ 138-184 è¡Œ

```typescript
const handleSubmit = async (e: React.FormEvent) => {
  const userMessage = input.trim();

  // 1. ç«‹å³æ˜¾ç¤ºç”¨æˆ·æ¶ˆæ¯ï¼ˆä¹è§‚æ›´æ–°ï¼‰
  setMessages((prev) => [
    ...prev,
    {
      id: `user-${Date.now()}`,
      role: "user",
      content: userMessage,
      timestamp: new Date(),
    },
  ]);

  // 2. å‘é€åˆ°åç«¯
  const response = await fetch(
    `/api/conversations/${conversationId}/messages`,
    {
      method: "POST",
      headers: { "Content-Type": "application/json" },
      body: JSON.stringify({ text: userMessage }),
    }
  );

  // 3. å»ºç«‹SSEè¿æ¥ç­‰å¾…AIå›å¤
  setTimeout(() => connectSSE(), 500);
};
```

**åç«¯å¤„ç†**: `src/app/api/conversations/[id]/messages/route.ts`

```typescript
export async function POST(request: NextRequest, { params }) {
  const { text } = await request.json();
  const { id: conversationId } = await params;

  // 1. éªŒè¯å¯¹è¯å­˜åœ¨
  const conversation = await prisma.conversation.findUnique({
    where: { id: conversationId },
  });

  // 2. ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
  const userMessage = await prisma.message.create({
    data: {
      convId: conversationId,
      role: "user",
      content: text,
    },
  });

  return NextResponse.json({ ok: true });
}
```

**æ•°æ®åº“å˜åŒ–**:

```sql
-- messages è¡¨æ–°å¢ç”¨æˆ·æ¶ˆæ¯
INSERT INTO messages (id, convId, role, content, createdAt)
VALUES ('msg_456', 'conv_123', 'user', 'æœ€è¿‘å·¥ä½œå‹åŠ›å¾ˆå¤§ï¼Œç»å¸¸åŠ ç­åˆ°å¾ˆæ™š', NOW());
```

---

### 3. AI ç¼–æ’å¼€å§‹ ğŸ¤–

#### æ­¥éª¤ 3ï¼šå»ºç«‹ SSE è¿æ¥ï¼Œè§¦å‘ AI ç¼–æ’

**å‰ç«¯ä»£ç **: `src/app/chat/[id]/page.tsx` ç¬¬ 39-127 è¡Œ

```typescript
const connectSSE = () => {
  // å»ºç«‹Server-Sent Eventsè¿æ¥
  eventSourceRef.current = new EventSource(
    `/api/conversations/${conversationId}/events`
  );

  eventSourceRef.current.onmessage = (event) => {
    const data = JSON.parse(event.data);

    switch (data.type) {
      case "step_started":
        console.log("å¼€å§‹æ‰§è¡Œæ­¥éª¤:", data.step);
        break;
      case "ai_message_started":
        // æ·»åŠ AIæ¶ˆæ¯å ä½ç¬¦
        setMessages((prev) => [
          ...prev,
          {
            id: `ai-${Date.now()}`,
            role: "ai",
            content: "",
            agentId: data.agent,
            isStreaming: true,
          },
        ]);
        break;
      case "ai_chunk":
        // å®æ—¶æ›´æ–°AIå›å¤å†…å®¹
        setMessages((prev) => {
          const newMessages = [...prev];
          const lastMessage = newMessages[newMessages.length - 1];
          if (lastMessage?.isStreaming) {
            lastMessage.content += data.text; // é€å­—è¿½åŠ 
          }
          return newMessages;
        });
        break;
    }
  };
};
```

**åç«¯å¤„ç†**: `src/app/api/conversations/[id]/events/route.ts`

```typescript
export async function GET(request: NextRequest, { params }) {
  const { id: conversationId } = await params;

  // 1. éªŒè¯å¯¹è¯å­˜åœ¨
  const conversation = await prisma.conversation.findUnique({
    where: { id: conversationId },
  });

  // 2. è·å–æœ€æ–°ç”¨æˆ·æ¶ˆæ¯
  const latestUserMessage = await prisma.message.findFirst({
    where: { convId: conversationId, role: "user" },
    orderBy: { createdAt: "desc" },
  });

  // 3. åˆ›å»ºæµå¼å“åº”
  const stream = new ReadableStream({
    start(controller) {
      const writeSSEEvent = (event) => {
        controller.enqueue(`data: ${JSON.stringify(event)}\n\n`);
      };

      // ğŸ”¥ å¼€å§‹AIç¼–æ’
      Orchestrator.runOrchestration(
        conversationId,
        latestUserMessage.content,
        writeSSEEvent
      );
    },
  });

  return new Response(stream, {
    headers: {
      "Content-Type": "text/event-stream",
      "Cache-Control": "no-cache",
    },
  });
}
```

---

### 4. AI ç¼–æ’æ‰§è¡Œ ğŸ­

#### æ­¥éª¤ 4ï¼šå¤š Agent æµç¨‹æ‰§è¡Œ

**æ ¸å¿ƒé€»è¾‘**: `src/lib/orchestrator.ts`

```typescript
export class Orchestrator {
  static async runOrchestration(conversationId, userMessageContent, onEvent) {
    // 1. è·å–å¯¹è¯æ¨¡å¼ï¼ˆå¦‚'empathy'ï¼‰
    const conversation = await prisma.conversation.findUnique({
      where: { id: conversationId },
    });

    // 2. è·å–æµç¨‹é…ç½®
    if (AgentConfigManager.isSingleProviderMode()) {
      // ä»é…ç½®æ–‡ä»¶è·å–ï¼šempathy â†’ [EMPATHY, PRACTICAL, FOLLOWUP]
      const flowConfig = AgentConfigManager.getFlowConfig(conversation.mode);
      steps = flowConfig.steps; // ['EMPATHY', 'PRACTICAL', 'FOLLOWUP']
    }

    let previousSummary = userMessageContent;

    // 3. ä¾æ¬¡æ‰§è¡Œæ¯ä¸ªAgent
    for (const roleTag of steps) {
      // EMPATHY â†’ PRACTICAL â†’ FOLLOWUP

      // 3.1 è·å–Agenté…ç½®
      const { agent, llmConfig } = AgentConfigManager.getAgentConfig(roleTag);
      /*
      agent = {
        roleTag: 'EMPATHY',
        name: 'å…±æƒ…è€…å°æš–',
        systemPrompt: 'ä½ æ˜¯ä¸€ä¸ªå¯Œæœ‰åŒç†å¿ƒçš„AIåŠ©æ‰‹...',
        temperature: 0.8
      }
      llmConfig = {
        provider: 'modelscope',
        model: 'qwen-turbo',
        apiKey: 'sk-xxx',
        baseUrl: 'https://dashscope.aliyuncs.com/compatible-mode/v1'
      }
      */

      // 3.2 å‘é€æ­¥éª¤å¼€å§‹äº‹ä»¶
      onEvent({ type: "step_started", step: roleTag });
      onEvent({ type: "ai_message_started", agent: roleTag });

      // 3.3 æ„å»ºæ¶ˆæ¯
      const messages = [
        {
          role: "system",
          content: agent.systemPrompt, // Agentçš„æç¤ºè¯
        },
        {
          role: "user",
          content: previousSummary, // ç”¨æˆ·æ¶ˆæ¯æˆ–ä¸Šä¸€ä¸ªAgentçš„å›å¤
        },
      ];

      // 3.4 ğŸ”¥ è°ƒç”¨LLMæœåŠ¡
      const response = await llmService.streamChat(
        llmConfig,
        messages,
        (chunk) => {
          // å®æ—¶å‘é€AIå›å¤ç‰‡æ®µ
          onEvent({ type: "ai_chunk", text: chunk.content });
        }
      );

      // 3.5 ä¿å­˜AIæ¶ˆæ¯åˆ°æ•°æ®åº“
      await prisma.message.create({
        data: {
          convId: conversationId,
          role: "ai",
          agentId: roleTag,
          content: response.content,
          tokens: response.usage.totalTokens,
        },
      });

      // 3.6 æ›´æ–°ä¸‹ä¸€è½®çš„è¾“å…¥
      previousSummary = response.content;
    }
  }
}
```

---

### 5. LLM æœåŠ¡è°ƒç”¨ ğŸ§ 

#### æ­¥éª¤ 5ï¼šæ¨¡å‹ API è°ƒç”¨

**æœåŠ¡å±‚**: `src/lib/llm-service.ts`

```typescript
class LLMService {
  async streamChat(config, messages, onChunk) {
    // 1. è·å–å¯¹åº”çš„é€‚é…å™¨
    const adapter = this.getAdapter(config.provider); // modelscope

    // 2. è°ƒç”¨é€‚é…å™¨
    return adapter.streamChat(config, messages, onChunk);
  }
}
```

**é­”æ­é€‚é…å™¨**: `src/lib/adapters/modelscope-adapter-simple.ts`

```typescript
export default class ModelScopeAdapter extends OpenAIAdapter {
  async streamChat(config, messages, onChunk) {
    // 1. è®¾ç½®é­”æ­ç«¯ç‚¹
    const modifiedConfig = {
      ...config,
      baseUrl: "https://dashscope.aliyuncs.com/compatible-mode/v1",
    };

    // 2. è°ƒç”¨çˆ¶ç±»OpenAIé€»è¾‘
    return super.streamChat(modifiedConfig, messages, onChunk);
  }
}
```

**OpenAI é€‚é…å™¨**: `src/lib/adapters/openai-adapter.ts`

```typescript
export default class OpenAIAdapter {
  async streamChat(config, messages, onChunk) {
    // 1. æ„å»ºAPIè¯·æ±‚
    const requestBody = {
      model: config.model,        // 'qwen-turbo'
      messages: messages,         // ç³»ç»Ÿæç¤ºè¯ + ç”¨æˆ·æ¶ˆæ¯
      temperature: 0.8,          // æ¥è‡ªAgenté…ç½®
      max_tokens: 1000,
      stream: true               // æµå¼è¾“å‡º
    };

    // 2. å‘é€è¯·æ±‚åˆ°é­”æ­API
    const response = await fetch(
      'https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions',
      {
        method: 'POST',
        headers: {
          'Authorization': `Bearer ${config.apiKey}`,
          'Content-Type': 'application/json',
        },
        body: JSON.stringify(requestBody),
      }
    );

    // 3. å¤„ç†æµå¼å“åº”
    const reader = response.body.getReader();
    let content = '';

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;

      const lines = new TextDecoder().decode(value).split('\n');

      for (const line of lines) {
        if (line.startsWith('data: ')) {
          const data = line.slice(6);
          if (data === '[DONE]') break;

          const parsed = JSON.parse(data);
          const delta = parsed.choices?.[0]?.delta?.content;

          if (delta) {
            content += delta;
            onChunk({ content: delta, isComplete: false });  // ğŸ”¥ å®æ—¶å›è°ƒ
          }
        }
      }
    }

    return { content, usage: {...}, model: 'qwen-turbo' };
  }
}
```

---

### 6. å‰ç«¯å®æ—¶æ˜¾ç¤º ğŸ“±

#### æ­¥éª¤ 6ï¼šæµå¼å†…å®¹æ˜¾ç¤º

**å‰ç«¯æ¥æ”¶**: `src/app/chat/[id]/page.tsx`

```typescript
// SSEäº‹ä»¶å¤„ç†
eventSourceRef.current.onmessage = (event) => {
  const data = JSON.parse(event.data);

  if (data.type === "ai_chunk") {
    // å®æ—¶æ›´æ–°æœ€åä¸€æ¡AIæ¶ˆæ¯
    setMessages((prev) => {
      const newMessages = [...prev];
      const lastMessage = newMessages[newMessages.length - 1];

      if (lastMessage?.role === "ai" && lastMessage.isStreaming) {
        lastMessage.content += data.text; // è¿½åŠ æ–°å†…å®¹
      }

      return newMessages;
    });
  }
};
```

**è§†è§‰æ•ˆæœ**:

```
ç”¨æˆ·: æœ€è¿‘å·¥ä½œå‹åŠ›å¾ˆå¤§ï¼Œç»å¸¸åŠ ç­åˆ°å¾ˆæ™š

AI (å…±æƒ…è€…å°æš–): æˆ‘
AI (å…±æƒ…è€…å°æš–): æˆ‘èƒ½
AI (å…±æƒ…è€…å°æš–): æˆ‘èƒ½æ„Ÿ
AI (å…±æƒ…è€…å°æš–): æˆ‘èƒ½æ„Ÿå—åˆ°ä½ ç°åœ¨çš„å‹åŠ›...
[ç»§ç»­é€å­—æ˜¾ç¤º]

AI (å»ºè®®è€…å°æ™º): åŸºäºä½ çš„æƒ…å†µï¼Œæˆ‘å»ºè®®...
[ç¬¬äºŒä¸ªAgentå¼€å§‹å›å¤]

AI (å…³æ€€è€…å°çˆ±): å¸Œæœ›æˆ‘çš„å»ºè®®èƒ½å¯¹ä½ æœ‰æ‰€å¸®åŠ©...
[ç¬¬ä¸‰ä¸ªAgentå®Œæˆæ•´ä¸ªæµç¨‹]
```

---

## ğŸ”„ å®Œæ•´æ•°æ®æµ

### æ•°æ®åº“è®°å½•å˜åŒ–

```sql
-- 1. åˆ›å»ºå¯¹è¯
conversations: conv_123 | user_1 | "å·¥ä½œå‹åŠ›å¾ˆå¤§" | "empathy"

-- 2. ç”¨æˆ·æ¶ˆæ¯
messages: msg_456 | conv_123 | "user" | "æœ€è¿‘å·¥ä½œå‹åŠ›å¾ˆå¤§..."

-- 3. AIå›å¤1 (å…±æƒ…è€…)
messages: msg_789 | conv_123 | "ai" | "EMPATHY" | "æˆ‘èƒ½æ„Ÿå—åˆ°ä½ ç°åœ¨çš„å‹åŠ›..."

-- 4. AIå›å¤2 (å»ºè®®è€…)
messages: msg_101 | conv_123 | "ai" | "PRACTICAL" | "åŸºäºä½ çš„æƒ…å†µï¼Œæˆ‘å»ºè®®..."

-- 5. AIå›å¤3 (å…³æ€€è€…)
messages: msg_112 | conv_123 | "ai" | "FOLLOWUP" | "å¸Œæœ›æˆ‘çš„å»ºè®®èƒ½å¯¹ä½ æœ‰æ‰€å¸®åŠ©..."
```

### API è°ƒç”¨åºåˆ—

```
1. POST /api/conversations â†’ åˆ›å»ºå¯¹è¯
2. POST /api/conversations/conv_123/messages â†’ ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
3. GET /api/conversations/conv_123/events â†’ å»ºç«‹SSEè¿æ¥
4. AIç¼–æ’å¼€å§‹æ‰§è¡Œ:
   - Agent1è°ƒç”¨: https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
   - Agent2è°ƒç”¨: https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
   - Agent3è°ƒç”¨: https://dashscope.aliyuncs.com/compatible-mode/v1/chat/completions
5. SSEæµå¼è¿”å›ç»“æœåˆ°å‰ç«¯
```

---

## ğŸ¯ å…³é”®é…ç½®æ–‡ä»¶

### æµç¨‹é…ç½®: `config/single-provider-agents.json`

```json
{
  "provider": "modelscope",
  "model": "qwen-turbo",
  "flows": [
    {
      "mode": "empathy",
      "steps": ["EMPATHY", "PRACTICAL", "FOLLOWUP"] // ğŸ”¥ å†³å®šæ‰§è¡Œé¡ºåº
    }
  ]
}
```

### ç¯å¢ƒé…ç½®: `.env.local`

```bash
MODELSCOPE_API_KEY="sk-xxx"  # ğŸ”‘ é­”æ­APIå¯†é’¥
DATABASE_URL="postgresql://..." # æ•°æ®åº“è¿æ¥
```

---

## ğŸš€ æ€»ç»“

**å®Œæ•´è·¯å¾„**:

1. **ç”¨æˆ·è¾“å…¥** â†’ å‰ç«¯è¡¨å•
2. **åˆ›å»ºå¯¹è¯** â†’ API ä¿å­˜åˆ°æ•°æ®åº“
3. **å‘é€æ¶ˆæ¯** â†’ API ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
4. **å»ºç«‹ SSE** â†’ æµå¼è¿æ¥
5. **AI ç¼–æ’** â†’ æ ¹æ®é…ç½®ä¾æ¬¡è°ƒç”¨å¤šä¸ª Agent
6. **æ¨¡å‹è°ƒç”¨** â†’ é­”æ­ API è¿”å›æµå¼å†…å®¹
7. **å®æ—¶æ˜¾ç¤º** â†’ å‰ç«¯é€å­—æ˜¾ç¤º AI å›å¤

**æ ¸å¿ƒç»„ä»¶**:

- **å‰ç«¯**: React + SSE å®æ—¶é€šä¿¡
- **åç«¯**: Next.js API Routes + Prisma
- **AI æœåŠ¡**: ç¼–æ’å™¨ + é€‚é…å™¨æ¨¡å¼
- **å¤–éƒ¨ API**: é­”æ­ç¤¾åŒºå…¼å®¹ OpenAI æ ¼å¼

ç°åœ¨è¿™ä¸ªæµç¨‹æ¸…æ¥šäº†å—ï¼Ÿæœ‰å“ªä¸ªç¯èŠ‚è¿˜éœ€è¦æˆ‘è¯¦ç»†è§£é‡Šï¼Ÿ
